{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import MSE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes):\n",
    "\t\t# initialize the model along with the input shape\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "\t\t# first CONV => RELU => BN layer set\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\",\n",
    "\t\t\tinput_shape=inputShape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\t# second CONV => RELU => BN layer set\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(128))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Dropout(0.5))\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_adversary(model, image, label, eps=2 / 255.0):\n",
    "\t# cast the image\n",
    "\timage = tf.cast(image, tf.float32)\n",
    "\t# record our gradients\n",
    "\twith tf.GradientTape() as tape:\n",
    "\t\t# explicitly indicate that our image should be tacked for\n",
    "\t\t# gradient updates\n",
    "\t\ttape.watch(image)\n",
    "\t\t# use our model to make predictions on the input image and\n",
    "\t\t# then compute the loss\n",
    "\t\tpred = model(image)\n",
    "\t\tloss = MSE(label, pred)\n",
    "\t\t# calculate the gradients of loss with respect to the image, then\n",
    "\t# compute the sign of the gradient\n",
    "\tgradient = tape.gradient(loss, image)\n",
    "\tsignedGrad = tf.sign(gradient)\n",
    "\t# construct the image adversary\n",
    "\tadversary = (image + (signedGrad * eps)).numpy()\n",
    "\t# return the image adversary to the calling function\n",
    "\treturn adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading MNIST dataset...\")\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "trainX = trainX / 255.0\n",
    "testX = testX / 255.0\n",
    "# add a channel dimension to the images\n",
    "trainX = np.expand_dims(trainX, axis=-1)\n",
    "testX = np.expand_dims(testX, axis=-1)\n",
    "# one-hot encode our labels\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "WARNING:tensorflow:From c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\anish\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 7s 6ms/step - loss: 0.1985 - accuracy: 0.9409 - val_loss: 0.0606 - val_accuracy: 0.9812\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 5s 6ms/step - loss: 0.0790 - accuracy: 0.9764 - val_loss: 0.0484 - val_accuracy: 0.9842\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.0586 - accuracy: 0.9821 - val_loss: 0.0444 - val_accuracy: 0.9852\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.0476 - accuracy: 0.9852 - val_loss: 0.0420 - val_accuracy: 0.9864\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0407 - accuracy: 0.9879 - val_loss: 0.0351 - val_accuracy: 0.9890\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0331 - accuracy: 0.9894 - val_loss: 0.0408 - val_accuracy: 0.9868\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.0377 - val_accuracy: 0.9875\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.0393 - val_accuracy: 0.9874\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 0.0577 - val_accuracy: 0.9833\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0372 - val_accuracy: 0.9886\n",
      "[INFO] loss: 0.0372, acc: 0.9886\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=1e-3)\n",
    "model = SimpleCNN.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "# train the simple CNN on MNIST\n",
    "print(\"[INFO] training network...\")\n",
    "model.fit(trainX, trainY,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tbatch_size=64,\n",
    "\tepochs=10,\n",
    "\tverbose=1)\n",
    "# make predictions on the testing set for the model trained on\n",
    "# non-adversarial images\n",
    "(loss, acc) = model.evaluate(x=testX, y=testY, verbose=0)\n",
    "print(\"[INFO] loss: {:.4f}, acc: {:.4f}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 138ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# loop over a sample of our testing images\n",
    "for i in np.random.choice(np.arange(0, len(testX)), size=(10,)):\n",
    "\t# grab the current image and label\n",
    "\timage = testX[i]\n",
    "\tlabel = testY[i]\n",
    "\t# generate an image adversary for the current image and make\n",
    "\t# a prediction on the adversary\n",
    "\tadversary = generate_image_adversary(model,\n",
    "\t\timage.reshape(1, 28, 28, 1), label, eps=0.1)\n",
    "\tpred = model.predict(adversary)\n",
    "\t# scale both the original image and adversary to the range\n",
    "\t# [0, 255] and convert them to an unsigned 8-bit integers\n",
    "\tadversary = adversary.reshape((28, 28)) * 255\n",
    "\tadversary = np.clip(adversary, 0, 255).astype(\"uint8\")\n",
    "\timage = image.reshape((28, 28)) * 255\n",
    "\timage = image.astype(\"uint8\")\n",
    "\t# convert the image and adversarial image from grayscale to three\n",
    "\t# channel (so we can draw on them)\n",
    "\timage = np.dstack([image] * 3)\n",
    "\tadversary = np.dstack([adversary] * 3)\n",
    "\t# resize the images so we can better visualize them\n",
    "\timage = cv2.resize(image, (96, 96))\n",
    "\tadversary = cv2.resize(adversary, (96, 96))\n",
    "\t# determine the predicted label for both the original image and\n",
    "\t# adversarial image\n",
    "\timagePred = label.argmax()\n",
    "\tadversaryPred = pred[0].argmax()\n",
    "\tcolor = (0, 255, 0)\n",
    "\t# if the image prediction does not match the adversarial\n",
    "\t# prediction then update the color\n",
    "\tif imagePred != adversaryPred:\n",
    "\t\tcolor = (0, 0, 255)\n",
    "\t# draw the predictions on the respective output images\n",
    "\tcv2.putText(image, str(imagePred), (2, 25),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.95, (0, 255, 0), 2)\n",
    "\tcv2.putText(adversary, str(adversaryPred), (2, 25),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.95, color, 2)\n",
    "\t# stack the two images horizontally and then show the original\n",
    "\t# image and adversarial image\n",
    "\toutput = np.hstack([image, adversary])\n",
    "\tcv2.imshow(\"FGSM Adversarial Images\", output)\n",
    "\tcv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
